import streamlit as st
import pandas as pd
import os
import zipfile
import shutil
from datetime import datetime
from io import BytesIO
import chardet
from openpyxl import load_workbook
import tempfile
import win32com.client
import pythoncom

st.set_page_config(page_title='Excelåˆ†å‰²åˆä½µå·¥å…·', page_icon='ğŸ“')

st.markdown("""
    <style>
    div.block-container {
        padding-top: 3.5rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
def detect_encoding(file):
    raw_data = file.read(10000)
    result = chardet.detect(raw_data)
    return result['encoding']

def read_uploaded_file(uploaded_file, header_rows=1):
    if uploaded_file.name.endswith(('.xlsx', '.xls')):
        df = pd.read_excel(uploaded_file, dtype={'é¸é …ID': str})
    elif uploaded_file.name.endswith('.csv'):
        uploaded_file.seek(0)
        encoding = detect_encoding(uploaded_file)
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, encoding=encoding, dtype={'é¸é …ID': str})
    else:
        df = None
    if df is not None:
        df = df.iloc[header_rows:]
    return df

def unprotect_excel_sheet(file_path):
    pythoncom.CoInitialize()
    excel = win32com.client.Dispatch("Excel.Application")
    excel.Visible = False
    try:
        # å˜—è©¦æ‰“é–‹ Excel æª”æ¡ˆï¼Œä¸¦è§£é™¤ä¿è­·
        workbook = excel.Workbooks.Open(os.path.abspath(file_path))
        for sheet in workbook.Sheets:
            sheet.Unprotect()
        # å„²å­˜æ›´æ”¹ä¸¦é—œé–‰æª”æ¡ˆ
        workbook.Save()
        workbook.Close(SaveChanges=True)
        print(f"{file_path} è§£é™¤ä¿è­·æˆåŠŸ")
    except Exception as e:
        print(f"è™•ç† {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    finally:
        # ç¢ºä¿æ­£ç¢ºé—œé–‰å·¥ä½œç°¿èˆ‡ Excel æ‡‰ç”¨ç¨‹å¼
        excel.Quit()
        pythoncom.CoUninitialize()

def unzip_and_unprotect(zip_file_path, extract_to, progress_bar, status_text):
    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)

    unprotected_files = []
    files = [f for f in os.listdir(extract_to) if f.endswith('.xlsx')]
    total_files = len(files)

    for idx, file in enumerate(files):
        file_path = os.path.join(extract_to, file)
        print(f"æ­£åœ¨è™•ç†: {file_path}")
        try:
            unprotect_excel_sheet(file_path)
            unprotected_files.append(file_path)
        except Exception as e:
            print(f"åœ¨è™•ç† {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè·³éæ­¤æª”æ¡ˆ: {e}")

        progress = (idx + 1) / total_files
        progress_bar.progress(progress)
        status_text.text(f"è§£é™¤ä¿è­·é€²åº¦: {idx + 1} / {total_files}")
    
    return unprotected_files

def split_by_unique_ids(df, split_column, split_size):
    unique_ids = df[split_column].unique()
    id_map = {ID: idx + 1 for idx, ID in enumerate(unique_ids)}
    df['ç·¨è™Ÿ'] = df[split_column].map(id_map)
    max_id = max(id_map.values())
    chunks = []
    log_details = []
    for num_start in range(1, max_id + 1, split_size):
        num_end = num_start + split_size - 1
        chunk = df[(df['ç·¨è™Ÿ'] >= num_start) & (df['ç·¨è™Ÿ'] <= num_end)].copy()
        if not chunk.empty:
            chunk = chunk.drop(columns=['ç·¨è™Ÿ'])
            chunks.append(chunk)
            num_rows = len(chunk)
            num_ids = chunk[split_column].nunique()
            log_details.append(f'åŒ…å« {num_rows} ç­†è³‡æ–™ï¼Œæ¶µè“‹ {num_ids} çµ„{split_column}')
    return chunks, log_details

def split_by_row_count(df, split_column, split_size):
    chunks = []
    current_chunk = []
    current_chunk_size = 0
    log_details = []
    grouped = df.groupby(split_column)
    for group, data in grouped:
        if current_chunk_size + len(data) <= split_size:
            current_chunk.append(data)
            current_chunk_size += len(data)
        else:
            chunks.append(pd.concat(current_chunk))
            current_chunk = [data]
            current_chunk_size = len(data)
    if current_chunk:
        chunks.append(pd.concat(current_chunk))
    for i, chunk in enumerate(chunks):
        num_rows = len(chunk)
        log_details.append(f'åŒ…å« {num_rows} ç­†è³‡æ–™')
    return chunks, log_details

def zip_output_directory(output_dir):
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        for foldername, subfolders, filenames in os.walk(output_dir):
            for filename in filenames:
                file_path = os.path.join(foldername, filename)
                zip_file.write(file_path, os.path.relpath(file_path, output_dir))
    zip_buffer.seek(0)
    return zip_buffer

def reset_file_uploader():
    st.session_state['split_file_uploader_key'] += 1
    st.session_state['merge_file_uploader_key'] += 1  

def main():
    if 'split_file_uploader_key' not in st.session_state:
        st.session_state['split_file_uploader_key'] = 0
    if 'merge_file_uploader_key' not in st.session_state:
        st.session_state['merge_file_uploader_key'] = 0

    tab1, tab2 = st.tabs(["Excelåˆ†å‰²", "Excelåˆä½µ"])

    with tab1:
        st.header("91APP EXCELåˆ†å‰²å·¥å…·")
        st.write("\n")
        col1, col2 = st.columns(2)

        with col1:
            split_logic = st.selectbox("é¸æ“‡åˆ†å‰²é‚è¼¯ (åŒçµ„è³‡æ–™å‡ä¸æ‹†æ•£)", ["è¨ˆç®—ä¸é‡è¦†IDæ•¸ (Shopeeæ¨¡å¼)", "è¨ˆç®—è¡¨æ ¼è¡Œæ•¸ (Yahooæ¨¡å¼)"])
            split_column_default = "å•†å“ ID" if split_logic == "è¨ˆç®—ä¸é‡è¦†IDæ•¸ (Shopeeæ¨¡å¼)" else "è³£å ´ç·¨è™Ÿ"
            split_column = st.text_input("åˆ†å‰²ä¾æ“šçš„æ¬„ä½æ¨™é¡Œ", value=split_column_default)

        with col2:
            header_rows = st.number_input("æ¨™é¡Œä½”å¹¾è¡Œ?", min_value=0, value=1, key="split")
            split_size_label = 'å„æª”æ¡ˆçš„ä¸é‡è¦†IDæ•¸' if split_logic == 'è¨ˆç®—ä¸é‡è¦†IDæ•¸ (Shopeeæ¨¡å¼)' else 'å„æª”æ¡ˆçš„è¡Œæ•¸ä¸Šé™'
            split_size = st.number_input(split_size_label, min_value=1, value=1000, key="split_size")

        uploaded_file = st.file_uploader("ä¸Šå‚³ CSV æˆ– EXCEL", type=['csv', 'xlsx'],
                                         key='split_file_uploader_' + str(st.session_state['split_file_uploader_key']))

        if uploaded_file is not None:
            start_split = st.button("é–‹å§‹åˆ†å‰²")
            if start_split:
                st.write("\n")
                progress_bar = st.progress(0)
                status_text = st.empty()
                status_text.text("é–‹å§‹è™•ç†æ–‡ä»¶ï¼Œè«‹ç¨å¾Œ...")
                
                df = read_uploaded_file(uploaded_file, header_rows=header_rows)
                if df is None:
                    st.error("ç„¡æ³•è®€å–ä¸Šå‚³çš„æª”æ¡ˆï¼Œè«‹ç¢ºèªæª”æ¡ˆæ ¼å¼æ˜¯å¦æ­£ç¢ºã€‚")
                    return             
                if split_column not in df.columns:
                    st.error(f"ä¸Šå‚³çš„æª”æ¡ˆä¸­æ‰¾ä¸åˆ° {split_column} æ¬„ä½ï¼Œè«‹é‡æ–°ç¢ºèªã€‚")
                    return
                    
                total_rows = len(df)
                today_date = datetime.now().strftime('%Y%m%d')
                output_dir = os.path.join(tempfile.gettempdir(), today_date)

                if os.path.exists(output_dir):
                    shutil.rmtree(output_dir)
                os.makedirs(output_dir, exist_ok=True)

                if split_logic == "è¨ˆç®—ä¸é‡è¦†IDæ•¸ (Shopeeæ¨¡å¼)":
                    chunks, log_details = split_by_unique_ids(df, split_column, split_size)
                else:
                    chunks, log_details = split_by_row_count(df, split_column, split_size)

                total_chunks = len(chunks)
                
                for idx, chunk in enumerate(chunks):
                    output_path = os.path.join(output_dir, f'{idx + 1}.xlsx')
                    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
                        chunk.to_excel(writer, index=False)
                        worksheet = writer.sheets['Sheet1']
                        for col_num, value in enumerate(chunk.columns.values):
                            worksheet.write(0, col_num, value)
                        if 'é¸é …ID' in chunk.columns:
                            format1 = writer.book.add_format({'num_format': '@'})
                            col_idx = chunk.columns.get_loc('é¸é …ID')
                            worksheet.set_column(col_idx, col_idx, None, format1)
                    progress_fraction = (idx + 1) / total_chunks
                    progress_bar.progress(progress_fraction)
                    status_text.text(f"è™•ç†é€²åº¦: {idx + 1} / {total_chunks}")

                progress_bar.empty()
                status_text.empty()

                log_file_path = os.path.join(output_dir, f'{today_date}_åˆ†å‰²log.txt')
                with open(log_file_path, 'w') as log_file:
                    log_file.write(f"ç¸½å…±è™•ç†äº† {total_rows} ç­†è³‡æ–™ï¼Œåˆ†æˆ {total_chunks} ä»½æª”æ¡ˆ\n")
                    for idx, log in enumerate(log_details):
                        log_file.write(f'ä¿å­˜æ–‡ä»¶: {idx + 1}.xlsxï¼Œ{log}\n')

                zip_buffer = zip_output_directory(output_dir)
                shutil.rmtree(output_dir)

                st.success("æª”æ¡ˆè™•ç†å®Œæˆï¼")

                st.download_button(
                    label="ä¸‹è¼‰åˆ†å‰²æª”æ¡ˆ",
                    data=zip_buffer,
                    file_name=f'{today_date}_åˆ†å‰².zip',
                    mime='application/zip',
                    on_click=reset_file_uploader
                )

    with tab2:
        st.header("91APP EXCELåˆä½µå·¥å…·")
        st.write("\n")
        header_rows = st.number_input("æ¨™é¡Œä½”å¹¾è¡Œ?", min_value=0, value=6, key="merge")
        uploaded_file = st.file_uploader("ä¸Šå‚³åŒ…å« CSV æˆ– EXCEL çš„ ZIP æª”", type=['zip'],
                                         key='merge_file_uploader_' + str(st.session_state['merge_file_uploader_key']))

        if uploaded_file is not None:
            start_merge = st.button("é–‹å§‹åˆä½µ")
            if start_merge:
                st.write("\n")
                        
                temp_dir = tempfile.mkdtemp()

                # å…ˆé¡¯ç¤ºé€²åº¦æ¢èˆ‡ç‹€æ…‹æ–‡å­—
                progress_bar = st.progress(0)
                status_text = st.empty()
                status_text.text("æ­£åœ¨è§£å£“ç¸®ä¸¦è§£é™¤å·¥ä½œè¡¨ä¿è­·ï¼Œè«‹ç¨å€™...")

                # æš«å­˜ ZIP æª”æ¡ˆä¸¦è§£å£“ç¸®å’Œè§£é™¤ä¿è­·
                with tempfile.NamedTemporaryFile(delete=False) as temp_zip:
                    temp_zip.write(uploaded_file.read())
                    temp_zip.close()

                    unprotected_files = unzip_and_unprotect(temp_zip.name, temp_dir, progress_bar, status_text)

                # å–æ¶ˆä¿è­·å®Œæˆå¾Œï¼Œé‡è¨­é€²åº¦æ¢å’Œç‹€æ…‹
                progress_bar.empty()
                status_text.empty()

                # é‡è¨­é€²åº¦æ¢ç‚º 0ï¼Œä¸¦é–‹å§‹åˆä½µ
                total_files = len(unprotected_files)
                progress_bar = st.progress(0)
                status_text = st.empty()
                merged_data = pd.DataFrame()

                # åˆä½µæª”æ¡ˆ
                header_workbook = None
                log_details = []
                today_date = datetime.now().strftime('%Y%m%d')

                for idx, file_path in enumerate(unprotected_files):
                    try:
                        workbook = load_workbook(file_path)
                        sheet = workbook.active

                        if header_workbook is None:
                            header_workbook = load_workbook(file_path)
                            merged_workbook = load_workbook(file_path)
                            merged_sheet = merged_workbook.active

                        for row in sheet.iter_rows(min_row=header_rows + 1, values_only=True):
                            merged_sheet.append(row)

                        log_details.append(f"æˆåŠŸè™•ç† Excel æª”æ¡ˆ: {os.path.basename(file_path)}")
                    except Exception as e:
                        log_details.append(f"ç„¡æ³•è®€å– Excel æª”æ¡ˆ {os.path.basename(file_path)}ï¼ŒéŒ¯èª¤è¨Šæ¯: {e}")

                    progress = (idx + 1) / total_files
                    progress_bar.progress(progress)
                    status_text.text(f"è™•ç†é€²åº¦: {idx + 1} / {total_files}")

                progress_bar.empty()
                status_text.empty()

                # å®Œæˆåˆä½µï¼Œæä¾›ä¸‹è¼‰
                with st.spinner('å°±å¿«å®Œæˆäº†...'):
                    output = BytesIO()
                    if 'merged_workbook' in locals():
                        merged_workbook.save(output)
                    output.seek(0)

                    log_output = BytesIO()
                    log_content = '\n'.join(log_details)
                    log_output.write(log_content.encode('utf-8'))
                    log_output.seek(0)

                    zip_buffer = BytesIO()
                    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
                        zip_file.writestr(f'{today_date}_åˆä½µ.xlsx', output.getvalue())
                        zip_file.writestr(f'{today_date}_åˆä½µlog.txt', log_output.getvalue())

                    zip_buffer.seek(0)

                shutil.rmtree(temp_dir)

                st.success("æª”æ¡ˆè™•ç†å®Œæˆï¼")
                
                st.download_button(
                    label="ä¸‹è¼‰åˆä½µæª”æ¡ˆ",
                    data=zip_buffer,
                    file_name=f'{today_date}_åˆä½µ.zip',
                    mime='application/zip'
                )

                
if __name__ == '__main__':
    main()
